{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53363334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf2643d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395302fb11ae4fcca32be91608634982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 4.13 s, total: 1min 22s\n",
      "Wall time: 1min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "datasets = {\n",
    "    'icm_5zty':'./data/5zty_screen_table_1M/results_single_sparse_v0.csv',\n",
    "    'icm_4eiy':'./data/4eiy_screen_table_1M/results_single_sparse_v0_uncut.csv',\n",
    "    'dock_D4'  :'./data/D4_screen_table_1M/results_single_sparse_v0.csv',\n",
    "    'dock_AmpC':'./data/AmpC_screen_table_1M/results_single_sparse_v0.csv',\n",
    "           }\n",
    "dataset_size = {'AmpC':96214206, 'D4':138312677, '4eiy':int(1e6),'5zty':int(1e6)}\n",
    "\n",
    "dfs = []\n",
    "for name, path in tqdm(datasets.items()):\n",
    "    if not path:\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path, index_col='Unnamed: 0').fillna(False)\n",
    "    df['proj'] = name\n",
    "    df['N_ligands'] = dataset_size.get(name)\n",
    "    datasets[name] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0600608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(dict):\n",
    "    pass\n",
    "datasets = Dataset(datasets)\n",
    "\n",
    "for name, value in datasets.items():\n",
    "    setattr(datasets, name, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76aa9d",
   "metadata": {},
   "source": [
    "Desired table for each dataset:\n",
    "\n",
    "\n",
    "`molecule : top_percentage : train_size : real_label : predicted_label`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_raw_predictions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca23e3c4dd600cc2c81ae106162a3ce508e5ba4d60641201e3aac6da197904fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
